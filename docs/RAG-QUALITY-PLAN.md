# FileFlux RAG Quality Plan

## ğŸ¯ ëª©í‘œ: RAG ê²€ìƒ‰ í’ˆì§ˆ ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ì²­í‚¹ ìµœì í™”

FileFluxëŠ” **RAG ì¤€ë¹„**ì—ë§Œ ì§‘ì¤‘í•©ë‹ˆë‹¤. ì„ë² ë”©, ì €ì¥, ê²€ìƒ‰, ê·¸ë˜í”„ëŠ” ì†Œë¹„ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì±…ì„ì…ë‹ˆë‹¤.

## ğŸ“Š RAG í’ˆì§ˆ ë©”íŠ¸ë¦­ (ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ)

### 1. ê²€ìƒ‰ ì¬í˜„ìœ¨ (Retrieval Recall)
- **ëª©í‘œ**: 85% ì´ìƒ
- **ì¸¡ì • ë°©ë²•**: ê´€ë ¨ ì²­í¬ê°€ ìƒìœ„ Kê°œ ê²°ê³¼ì— í¬í•¨ë˜ëŠ” ë¹„ìœ¨
- **í…ŒìŠ¤íŠ¸**: `RAGQualityBenchmark.TestRetrievalRecall()`

### 2. ì²­í¬ ì™„ì „ì„± (Chunk Completeness)
- **ëª©í‘œ**: 90% ì´ìƒ
- **ì¸¡ì • ë°©ë²•**: ì²­í¬ê°€ ë…ë¦½ì ìœ¼ë¡œ ì´í•´ ê°€ëŠ¥í•œ ì •ë³´ í¬í•¨ ë¹„ìœ¨
- **í…ŒìŠ¤íŠ¸**: `ChunkCompletenessTests.TestStandaloneReadability()`

### 3. ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ìœ¨ (Context Preservation)
- **ëª©í‘œ**: 95% ì´ìƒ
- **ì¸¡ì • ë°©ë²•**: ì›ë³¸ ë¬¸ì„œì˜ ì˜ë¯¸ê°€ ì²­í¬ì— ë³´ì¡´ë˜ëŠ” ë¹„ìœ¨
- **í…ŒìŠ¤íŠ¸**: `ContextPreservationTests.TestSemanticIntegrity()`

### 4. ê²½ê³„ ì •í™•ë„ (Boundary Accuracy)
- **ëª©í‘œ**: 90% ì´ìƒ
- **ì¸¡ì • ë°©ë²•**: ì˜ë¯¸ì  ê²½ê³„ê°€ ì˜¬ë°”ë¥´ê²Œ ê°ì§€ë˜ëŠ” ë¹„ìœ¨
- **í…ŒìŠ¤íŠ¸**: `BoundaryDetectionTests.TestSemanticBoundaries()`

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê¸°ë°˜ êµ¬í˜„ ê³„íš

### Phase 11-A: RAG í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ êµ¬ì¶•

#### 1. RAGQualityBenchmark í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
```csharp
public class RAGQualityBenchmark
{
    [Fact]
    public async Task TestRetrievalRecall_ShouldAchieve85Percent()
    {
        // Arrange: ì‹¤ì œ QA ìŒê³¼ ë¬¸ì„œ ì¤€ë¹„
        var testData = LoadRAGBenchmarkData();
        var processor = new DocumentProcessor();
        
        // Act: ë¬¸ì„œ ì²­í‚¹
        var chunks = await processor.ProcessAsync(testData.Document);
        
        // Assert: ê²€ìƒ‰ ì¬í˜„ìœ¨ ì¸¡ì •
        var recall = CalculateRetrievalRecall(testData.Questions, chunks);
        Assert.True(recall >= 0.85, $"Recall {recall:P} is below 85%");
    }
    
    [Theory]
    [InlineData("technical", 500, 800)]  // ê¸°ìˆ  ë¬¸ì„œ: 500-800 í† í°
    [InlineData("legal", 300, 500)]      // ë²•ë¥  ë¬¸ì„œ: 300-500 í† í°
    [InlineData("narrative", 800, 1200)] // ì„œì‚¬ ë¬¸ì„œ: 800-1200 í† í°
    public async Task TestOptimalChunkSize_ByDocumentType(
        string docType, int minSize, int maxSize)
    {
        // ë¬¸ì„œ íƒ€ì…ë³„ ìµœì  ì²­í¬ í¬ê¸° ê²€ì¦
    }
}
```

#### 2. ì²­í¬ í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸
```csharp
public class ChunkQualityTests
{
    [Fact]
    public void TestChunkCompleteness_ShouldBeStandalone()
    {
        // ê° ì²­í¬ê°€ ë…ë¦½ì ìœ¼ë¡œ ì½ì„ ìˆ˜ ìˆëŠ”ì§€ ê²€ì¦
        var chunk = CreateTestChunk();
        
        // ì™„ì „ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸
        Assert.True(HasSubjectContext(chunk));     // ì£¼ì–´ ì»¨í…ìŠ¤íŠ¸
        Assert.True(HasCompleteInformation(chunk)); // ì™„ì „í•œ ì •ë³´
        Assert.True(IsReadableAlone(chunk));       // ë…ë¦½ ê°€ë…ì„±
    }
    
    [Fact]
    public void TestOverlapEffectiveness()
    {
        // ì˜¤ë²„ë©ì´ ì»¨í…ìŠ¤íŠ¸ ì—°ê²°ì— íš¨ê³¼ì ì¸ì§€ ê²€ì¦
        var overlap = 128;
        var chunks = CreateChunksWithOverlap(overlap);
        
        Assert.True(CanReconstructContext(chunks));
        Assert.True(NoInformationLoss(chunks));
    }
}
```

#### 3. ê²½ê³„ ê°ì§€ ì •í™•ë„ í…ŒìŠ¤íŠ¸
```csharp
public class BoundaryDetectionAccuracyTests
{
    [Theory]
    [InlineData("# Heading\nContent", BoundaryType.Section)]
    [InlineData("```python\ncode\n```", BoundaryType.CodeBlock)]
    [InlineData("| Col1 | Col2 |", BoundaryType.Table)]
    [InlineData("1. Item\n2. Item", BoundaryType.List)]
    public void TestStructuralBoundaryDetection(
        string content, BoundaryType expectedType)
    {
        // êµ¬ì¡°ì  ê²½ê³„ ê°ì§€ ì •í™•ë„ ê²€ì¦
        var detector = new SemanticBoundaryDetector();
        var boundary = detector.DetectBoundary(content);
        
        Assert.Equal(expectedType, boundary.Type);
        Assert.True(boundary.Confidence > 0.8);
    }
}
```

### Phase 11-B: RAG ìµœì í™” êµ¬í˜„

#### 1. ì ì‘í˜• ì²­í‚¹ ê°œì„ 
```csharp
public interface IRAGOptimizedChunker
{
    /// <summary>
    /// RAG ê²€ìƒ‰ í’ˆì§ˆì— ìµœì í™”ëœ ì²­í‚¹
    /// </summary>
    Task<IEnumerable<DocumentChunk>> ChunkForRAGAsync(
        ParsedDocumentContent content,
        RAGOptimizationOptions options);
}

public class RAGOptimizationOptions
{
    /// <summary>
    /// ëª©í‘œ ê²€ìƒ‰ ì¬í˜„ìœ¨
    /// </summary>
    public double TargetRecall { get; set; } = 0.85;
    
    /// <summary>
    /// ì²­í¬ ë…ë¦½ì„± ìˆ˜ì¤€ (0-1)
    /// </summary>
    public double ChunkIndependence { get; set; } = 0.9;
    
    /// <summary>
    /// ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸°
    /// </summary>
    public int ContextWindow { get; set; } = 200;
    
    /// <summary>
    /// ë©”íƒ€ë°ì´í„° í’ë¶€ë„
    /// </summary>
    public MetadataRichness MetadataLevel { get; set; } = MetadataRichness.Full;
}
```

#### 2. ë©”íƒ€ë°ì´í„° í’ˆì§ˆ ê°•í™”
```csharp
public class EnhancedChunkMetadata : DocumentMetadata
{
    /// <summary>
    /// êµ¬ì¡°ì  ì—­í•  (ì œëª©, ë³¸ë¬¸, ìº¡ì…˜, ì°¸ì¡°)
    /// </summary>
    public StructuralRole Role { get; set; }
    
    /// <summary>
    /// ê³„ì¸µ êµ¬ì¡° ê²½ë¡œ (e.g., "Chapter 1 > Section 2 > Subsection 3")
    /// </summary>
    public string HierarchicalPath { get; set; }
    
    /// <summary>
    /// ì²­í¬ ì¤‘ìš”ë„ ì ìˆ˜ (0-1)
    /// </summary>
    public double ImportanceScore { get; set; }
    
    /// <summary>
    /// ì´ì „/ë‹¤ìŒ ì²­í¬ ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
    /// </summary>
    public string PreviousContext { get; set; }
    public string NextContext { get; set; }
    
    /// <summary>
    /// ê²€ìƒ‰ íŒíŠ¸ í‚¤ì›Œë“œ
    /// </summary>
    public List<string> SearchHints { get; set; }
}
```

### Phase 11-C: ì„±ëŠ¥ ê²€ì¦

#### 1. ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
```csharp
[Fact]
public async Task TestLargeDocumentProcessing_Under10Seconds()
{
    // 100MB ë¬¸ì„œë¥¼ 10ì´ˆ ë‚´ ì²˜ë¦¬
    var largeDoc = GenerateLargeDocument(100_000_000);
    var stopwatch = Stopwatch.StartNew();
    
    await foreach (var chunk in processor.ProcessStreamAsync(largeDoc))
    {
        // ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    }
    
    stopwatch.Stop();
    Assert.True(stopwatch.Elapsed.TotalSeconds < 10);
}
```

#### 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê²€ì¦
```csharp
[Fact]
public void TestMemoryEfficiency_Under2xFileSize()
{
    var fileSize = 50_000_000; // 50MB
    var memoryBefore = GC.GetTotalMemory(true);
    
    ProcessLargeFile(fileSize);
    
    var memoryUsed = GC.GetTotalMemory(false) - memoryBefore;
    Assert.True(memoryUsed < fileSize * 2);
}
```

## ğŸ“ˆ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Week 1: í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ êµ¬ì¶•
1. âœ… RAGQualityBenchmark í´ë˜ìŠ¤ ìƒì„±
2. âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ (QA pairs, documents)
3. âœ… ë©”íŠ¸ë¦­ ì¸¡ì • ìœ í‹¸ë¦¬í‹° êµ¬í˜„

### Week 2: í’ˆì§ˆ ê°œì„  êµ¬í˜„
1. âœ… ê²½ê³„ ê°ì§€ ì •í™•ë„ í–¥ìƒ
2. âœ… ë©”íƒ€ë°ì´í„° í’ë¶€í™”
3. âœ… ì²­í¬ ì™„ì „ì„± ê²€ì¦ ë¡œì§

### Week 3: ì„±ëŠ¥ ìµœì í™”
1. âœ… ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ê²€ì¦
2. âœ… ë³‘ë ¬ ì²˜ë¦¬ ì•ˆì •ì„±
3. âœ… ìºì‹± íš¨ê³¼ì„± ì¸¡ì •

### Week 4: ë¦´ë¦¬ì¦ˆ ì¤€ë¹„
1. âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (220/220)
2. âœ… ë¬¸ì„œí™” ì™„ì„±
3. âœ… NuGet íŒ¨í‚¤ì§€ ë°°í¬

## ğŸš« ë²”ìœ„ ì œì™¸ (ì†Œë¹„ ì•± ì±…ì„)

- âŒ ì„ë² ë”© ìƒì„± (OpenAI, Cohere, etc.)
- âŒ ë²¡í„° ì €ì¥ì†Œ í†µí•© (Pinecone, Qdrant, etc.)
- âŒ ìœ ì‚¬ë„ ê²€ìƒ‰ êµ¬í˜„
- âŒ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•
- âŒ RAG ì‘ë‹µ ìƒì„±
- âŒ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ë­í‚¹

## âœ… FileFlux í•µì‹¬ ê°€ì¹˜

1. **ì²­í‚¹ í’ˆì§ˆ**: RAG ê²€ìƒ‰ì— ìµœì í™”ëœ ì˜ë¯¸ì  ì²­í‚¹
2. **ë©”íƒ€ë°ì´í„°**: ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í’ë¶€í•œ ë©”íƒ€ë°ì´í„°
3. **ì„±ëŠ¥**: ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ê³ ì† ì²˜ë¦¬
4. **ì‹ ë¢°ì„±**: 100% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
5. **ê°„í¸í•¨**: ë‹¨ìˆœí•œ API, ë³µì¡í•œ ë‚´ë¶€ ì²˜ë¦¬

## ğŸ“ ì„±ê³µ ê¸°ì¤€

- [ ] ê²€ìƒ‰ ì¬í˜„ìœ¨ 85% ì´ìƒ ë‹¬ì„±
- [ ] ì²­í¬ ì™„ì „ì„± 90% ì´ìƒ ë‹¬ì„±
- [ ] 100MB ë¬¸ì„œ 10ì´ˆ ë‚´ ì²˜ë¦¬
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŒŒì¼ í¬ê¸°ì˜ 2ë°° ì´í•˜
- [ ] 220ê°œ í…ŒìŠ¤íŠ¸ 100% í†µê³¼
- [ ] NuGet ë‹¤ìš´ë¡œë“œ 1000+ ë‹¬ì„±