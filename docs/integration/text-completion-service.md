# ITextCompletionService Integration Guide

> **FileFlux Philosophy**: We define the interface. You implement it. We stay neutral.

## Overview

`ITextCompletionService` is FileFlux's abstraction for AI-powered document analysis. This interface enables:
- Intelligent document structure analysis
- Content summarization for metadata enrichment
- Quality assessment for RAG optimization
- Metadata extraction from unstructured content

**Key Point:** FileFlux generates prompts and processes results. YOU implement the AI service calls.

---

## Interface Contract

### Location
`FileFlux.Core.ITextCompletionService`

### Design Principles

1. **Provider Agnostic**: Works with OpenAI, Azure, Anthropic, local models, or any LLM
2. **Optional Dependency**: FileFlux works WITHOUT this service (uses fallbacks)
3. **Separation of Concerns**: FileFlux handles RAG logic, you handle AI calls

---

## Method Specifications

### 1. AnalyzeStructureAsync

**Purpose:** Analyze document structure for intelligent chunking

```csharp
Task<StructureAnalysisResult> AnalyzeStructureAsync(
    string prompt,
    DocumentType documentType,
    CancellationToken cancellationToken = default);
```

**Contract Requirements:**

| Aspect | Requirement |
|--------|-------------|
| Input | `prompt`: Structure analysis prompt generated by FileFlux |
| Input | `documentType`: PDF, DOCX, Markdown, etc. |
| Output | `StructureAnalysisResult` with sections and hierarchy |
| Error Handling | Return empty sections list, never null |
| Performance | Should complete within 10 seconds for typical documents |

**Output Structure:**

```csharp
public class StructureAnalysisResult
{
    DocumentType DocumentType;           // Echo back the input type
    List<SectionInfo> Sections;          // Detected sections (required)
    CoreDocumentStructure Structure;     // Hierarchical tree (required)
    double Confidence;                   // 0.0-1.0 confidence score
    string RawResponse;                  // Original LLM response
    int TokensUsed;                      // For cost tracking
}
```

**What FileFlux Does:**
- Generates optimal prompt for structure detection
- Provides document type context
- Processes returned sections for chunking decisions

**What You Implement:**
1. Call your chosen LLM with the provided prompt
2. Parse LLM response into `StructureAnalysisResult`
3. Extract sections, titles, and hierarchy
4. Return structured result

---

### 2. SummarizeContentAsync

**Purpose:** Generate content summaries for metadata enrichment

```csharp
Task<ContentSummary> SummarizeContentAsync(
    string prompt,
    int maxLength = 200,
    CancellationToken cancellationToken = default);
```

**Contract Requirements:**

| Aspect | Requirement |
|--------|-------------|
| Input | `prompt`: Content to summarize (generated by FileFlux) |
| Input | `maxLength`: Maximum summary length in characters |
| Output | `ContentSummary` with summary text and keywords |
| Constraint | Summary MUST respect `maxLength` |
| Keywords | Minimum 3 keywords, maximum 10 |

**Output Structure:**

```csharp
public class ContentSummary
{
    string Summary;                      // Summary text (required, respect maxLength)
    string[] Keywords;                   // Key terms (3-10 items)
    double Confidence;                   // 0.0-1.0 confidence score
    int OriginalLength;                  // Input text length
    int TokensUsed;                      // For cost tracking
}
```

**Implementation Tips:**
- Use LLM's max_tokens parameter to enforce length
- Extract keywords from summary or use separate keyword extraction
- Track token usage for cost monitoring

---

### 3. ExtractMetadataAsync

**Purpose:** Extract rich metadata from document content

```csharp
Task<MetadataExtractionResult> ExtractMetadataAsync(
    string prompt,
    DocumentType documentType,
    CancellationToken cancellationToken = default);
```

**Contract Requirements:**

| Aspect | Requirement |
|--------|-------------|
| Input | `prompt`: Content for metadata extraction |
| Input | `documentType`: Document type context |
| Output | `MetadataExtractionResult` with keywords, categories, entities |
| Minimum | Keywords and Language must be populated |
| Optional | Categories, Entities, TechnicalMetadata |

**Output Structure:**

```csharp
public class MetadataExtractionResult
{
    string[] Keywords;                                    // Required, 5-15 items
    string? Language;                                     // Required, ISO code (e.g., "en", "ko")
    string[] Categories;                                  // Optional, document categories
    Dictionary<string, string[]> Entities;                // Optional, named entities
    Dictionary<string, string> TechnicalMetadata;         // Optional, tech-specific metadata
    double Confidence;                                    // 0.0-1.0
    int TokensUsed;                                       // For cost tracking
}
```

**Entity Types (if supported):**
- `Person`: People names
- `Organization`: Company names
- `Location`: Places
- `Technology`: Programming languages, frameworks
- `Concept`: Domain-specific terms

---

### 4. AssessQualityAsync

**Purpose:** Evaluate chunk quality for RAG optimization

```csharp
Task<QualityAssessment> AssessQualityAsync(
    string prompt,
    CancellationToken cancellationToken = default);
```

**Contract Requirements:**

| Aspect | Requirement |
|--------|-------------|
| Input | `prompt`: Chunk content to assess |
| Output | `QualityAssessment` with scores and recommendations |
| Scores | All scores MUST be in range 0.0-1.0 |
| Recommendations | At least 1 recommendation if score < 0.7 |

**Output Structure:**

```csharp
public class QualityAssessment
{
    double ConfidenceScore;              // 0.0-1.0, content reliability
    double CompletenessScore;            // 0.0-1.0, information completeness
    double ConsistencyScore;             // 0.0-1.0, internal consistency
    List<QualityRecommendation> Recommendations;  // Improvement suggestions
    string Explanation;                  // Human-readable assessment
    int TokensUsed;                      // For cost tracking
}
```

**Quality Dimensions:**
- **Confidence**: Is the information reliable and authoritative?
- **Completeness**: Does the chunk contain complete information?
- **Consistency**: Is the chunk internally consistent?

---

### 5. GenerateAsync (Basic Completion)

**Purpose:** Simple text completion for generic use cases

```csharp
Task<string> GenerateAsync(
    string prompt,
    CancellationToken cancellationToken = default);
```

**Contract Requirements:**

| Aspect | Requirement |
|--------|-------------|
| Input | `prompt`: Raw prompt text |
| Output | Completion text as string |
| Error Handling | Return empty string on failure, NEVER throw |
| Use Case | Fallback for simple completions |

**When Used:**
- Quick responses without structured parsing
- Fallback when structured methods aren't needed
- Internal FileFlux operations requiring simple completions

---

### 6. IsAvailableAsync

**Purpose:** Check service availability before use

```csharp
Task<bool> IsAvailableAsync(CancellationToken cancellationToken = default);
```

**Contract Requirements:**

| Aspect | Requirement |
|--------|-------------|
| Output | `true` if service is ready, `false` otherwise |
| Check | Should verify API connectivity, not just configuration |
| Performance | MUST complete within 2 seconds |
| Caching | Consider caching result for 30-60 seconds |

**What to Check:**
1. API key/credentials configured
2. Network connectivity to AI service
3. Service quota not exceeded
4. Service endpoint responding

**FileFlux Behavior:**
- If `IsAvailableAsync()` returns `false`, FileFlux uses non-AI fallbacks
- Check is performed once at service initialization
- Re-checked after failures

---

### 7. ProviderInfo Property

**Purpose:** Service metadata for logging and debugging

```csharp
TextCompletionServiceInfo ProviderInfo { get; }
```

**Required Fields:**

```csharp
public class TextCompletionServiceInfo
{
    string Name;                         // Provider name (e.g., "OpenAI GPT-4")
    TextCompletionProviderType Type;     // OpenAI, Azure, Anthropic, Custom
    string[] SupportedModels;            // Models you support
    int MaxContextLength;                // Max tokens your service accepts
    decimal InputTokenCost;              // Cost per 1K input tokens (optional)
    decimal OutputTokenCost;             // Cost per 1K output tokens (optional)
    string ApiVersion;                   // API version (e.g., "2024-02-01")
}
```

**Used For:**
- Logging and telemetry
- Cost estimation
- Debugging integration issues
- Context length validation

---

## Implementation Checklist

When implementing `ITextCompletionService`:

### Required
- ✅ Implement all 7 methods
- ✅ Return valid objects (never null)
- ✅ Respect `maxLength` in SummarizeContentAsync
- ✅ All scores in range 0.0-1.0
- ✅ Populate ProviderInfo property
- ✅ Handle cancellation tokens
- ✅ Return empty/default on errors (don't throw)

### Recommended
- ✅ Track token usage in responses
- ✅ Cache availability status
- ✅ Log LLM responses for debugging
- ✅ Configure timeouts (5-10 seconds)
- ✅ Implement retry logic for transient failures
- ✅ Validate response formats

### Optional
- ⚪ Implement response streaming
- ⚪ Support multiple models
- ⚪ Provide custom prompts
- ⚪ Add cost tracking

---

## Error Handling Guidelines

**FileFlux expects graceful degradation:**

```csharp
public async Task<StructureAnalysisResult> AnalyzeStructureAsync(...)
{
    try
    {
        // Your LLM call
        var response = await _client.CompleteAsync(prompt);
        return ParseResponse(response);
    }
    catch (Exception ex)
    {
        _logger.LogError(ex, "Structure analysis failed");

        // Return valid empty result, don't throw
        return new StructureAnalysisResult
        {
            DocumentType = documentType,
            Sections = new List<SectionInfo>(),  // Empty, not null
            Structure = new CoreDocumentStructure(),
            Confidence = 0.0,
            TokensUsed = 0
        };
    }
}
```

**Why:** FileFlux has fallback mechanisms. Throwing exceptions breaks the processing pipeline.

---

## Testing Your Implementation

FileFlux provides `MockTextCompletionService` as a reference.

**Location:** `FileFlux.Tests.Mocks.MockTextCompletionService`

**Use it to:**
1. Understand expected return types
2. See how FileFlux processes responses
3. Test your implementation behavior

**Testing Pattern:**

```csharp
[Fact]
public async Task MyService_Should_ReturnValidStructure()
{
    // Arrange
    var myService = new MyTextCompletionService();
    var prompt = "Analyze this document...";

    // Act
    var result = await myService.AnalyzeStructureAsync(
        prompt,
        DocumentType.Markdown);

    // Assert
    Assert.NotNull(result);
    Assert.NotNull(result.Sections);  // Never null
    Assert.InRange(result.Confidence, 0.0, 1.0);  // Valid range
}
```

---

## Next Steps

1. **Implement your service** following this contract
2. **Register with DI** - See [Dependency Injection Guide](../configuration/dependency-injection.md)
3. **Test thoroughly** - Use Mock as reference
4. **Consider sharing** - Add to [Community Implementations](../community/implementations.md)

---

## Related Documentation

- [IImageToTextService Integration](image-to-text-service.md) - Multimodal support
- [Quality Analysis Features](../features/quality-analysis.md) - Using AI for quality assessment
- [Dependency Injection Patterns](../configuration/dependency-injection.md) - Service registration
- [Mock Implementations](../testing/mock-implementations.md) - Testing reference

---

## FAQ

**Q: Do I need to implement all methods?**
A: Yes, but you can return basic/empty results if not supporting a feature.

**Q: What if my LLM doesn't support structured output?**
A: Parse the text response into required objects. See Mock for examples.

**Q: Can I use different models for different methods?**
A: Absolutely! Optimize cost vs quality per method.

**Q: Should I cache responses?**
A: Yes, especially for expensive operations. FileFlux may call the same content multiple times.

**Q: What about rate limiting?**
A: Implement retry with exponential backoff. FileFlux respects your service limits.

**Q: Can I add custom methods?**
A: FileFlux won't use them, but you can extend the interface for your needs.

---

**Need Help?** Check [Community Implementations](../community/implementations.md) for working examples.
