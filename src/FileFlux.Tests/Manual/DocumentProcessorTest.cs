using FileFlux.Core;
using FileFlux.Infrastructure;
using FileFlux.Infrastructure.Factories;
using FileFlux.Domain;
using FileFlux.Tests.Mocks;
using Microsoft.Extensions.Logging;
using Xunit;

namespace FileFlux.Tests.Manual;

/// <summary>
/// DocumentProcessor ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (Extract â†’ Parse â†’ Chunk)
/// </summary>
public class DocumentProcessorTest
{
    private readonly ILogger<DocumentProcessorTest> _logger;
    private const string TestDataPath = @"D:\data\FileFlux\test";

    public DocumentProcessorTest()
    {
        using var loggerFactory = LoggerFactory.Create(builder => builder.AddConsole());
        _logger = loggerFactory.CreateLogger<DocumentProcessorTest>();
    }

    [Fact]
    public async Task TestCompleteProcessingPipeline()
    {
        // Arrange: Mock services ìƒì„±
        var mockTextCompletion = new MockTextCompletionService();
        var readerFactory = new DocumentReaderFactory();
        var parserFactory = new DocumentParserFactory(mockTextCompletion);
        var chunkingFactory = CreateChunkingFactory();

        IDocumentProcessor processor = new DocumentProcessor(
            readerFactory,
            parserFactory,
            chunkingFactory);

        var testFile = Path.Combine(TestDataPath, "test-markdown", "test.md");
        
        if (!File.Exists(testFile))
        {
            _logger.LogWarning("Test file not found: {TestFile}. Skipping test.", testFile);
            return;
        }

        var options = new ChunkingOptions
        {
            Strategy = ChunkingStrategies.FixedSize,
            MaxChunkSize = 500,
            OverlapSize = 50
        };

        var parsingOptions = new DocumentParsingOptions
        {
            UseAdvancedParsing = false, // Using basic rule-based parsing
            StructuringLevel = StructuringLevel.Low
        };

        _logger.LogInformation("ğŸ§ª Complete pipeline test starting");
        _logger.LogInformation("ğŸ“„ File: {TestFile}", testFile);
        _logger.LogInformation("ğŸ“‹ Strategy: {Strategy}", options.Strategy);

        // Act: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ìƒˆë¡œìš´ ProcessChunksAsync API ì‚¬ìš©)
        var chunks = new List<DocumentChunk>();
        
        await foreach (var chunk in processor.ProcessChunksAsync(testFile, options))
        {
            chunks.Add(chunk);
            _logger.LogInformation("âœ… Added chunk #{Index}: {Length} chars", 
                chunk.ChunkIndex, chunk.Content.Length);
        }
        
        var summaryMessage = $"ğŸ‰ Pipeline completed: {chunks.Count} chunks generated";
        _logger.LogInformation(summaryMessage);
        Console.WriteLine(summaryMessage);

        // Assert
        _logger.LogInformation("ğŸ‰ Final result: {ChunkCount} chunks generated", chunks.Count);

        // ì²­í¬ ìƒì„± ê²€ì¦
        Assert.True(chunks.Count > 0, $"Should generate at least one chunk, got {chunks.Count}");
        
        foreach (var chunk in chunks.Take(3))
        {
            Assert.NotNull(chunk.Content);
            Assert.True(chunk.Content.Length > 0);
            _logger.LogInformation("ğŸ“‹ Chunk {Index}: {Preview}...", 
                chunk.ChunkIndex, 
                chunk.Content.Length > 100 ? string.Concat(chunk.Content.AsSpan(0, 100), "...") : chunk.Content);
        }

        _logger.LogInformation("âœ… All assertions passed!");
    }

    private static ChunkingStrategyFactory CreateChunkingFactory()
    {
        var factory = new ChunkingStrategyFactory();
        
        // Register all chunking strategies manually (same as ServiceCollectionExtensions)
        factory.RegisterStrategy(() => new Infrastructure.Strategies.FixedSizeChunkingStrategy());
        factory.RegisterStrategy(() => new Infrastructure.Strategies.SemanticChunkingStrategy());
        factory.RegisterStrategy(() => new Infrastructure.Strategies.ParagraphChunkingStrategy());
        factory.RegisterStrategy(() => new Infrastructure.Strategies.IntelligentChunkingStrategy());
        
        return factory;
    }
}

