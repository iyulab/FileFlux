using FileFlux;
using FileFlux.Domain;
using FileFlux.Infrastructure;
using FileFlux.Infrastructure.Strategies;
using FileFlux.RealWorldBenchmark.Services;
using System.Text.Json;

namespace FileFlux.RealWorldBenchmark.Benchmarks;

/// <summary>
/// RAG í’ˆì§ˆ ë¹„êµ ë²¤ì¹˜ë§ˆí¬ - SmartChunking vs ê¸°ì¡´ ì „ëµë“¤
/// </summary>
public class RAGQualityComparison
{
    private readonly IDocumentProcessor _processor;
    private readonly OpenAiEmbeddingService _embeddingService;
    private readonly List<string> _testStrategies;
    private readonly Dictionary<string, List<TestResult>> _results;

    public RAGQualityComparison(IDocumentProcessor processor, OpenAiEmbeddingService embeddingService)
    {
        _processor = processor;
        _embeddingService = embeddingService;
        _testStrategies = new[] { "Smart", "Intelligent", "Semantic", "FixedSize" }.ToList();
        _results = new Dictionary<string, List<TestResult>>();
    }

    /// <summary>
    /// ì²­í‚¹ ì „ëµë³„ RAG í’ˆì§ˆ ë¹„êµ ì‹¤í–‰
    /// </summary>
    public async Task<ComparisonReport> RunComparisonAsync(string testDocument, List<string> testQueries, CancellationToken cancellationToken = default)
    {
        Console.WriteLine("ğŸš€ RAG Quality Comparison Started");
        Console.WriteLine("=================================");
        
        var report = new ComparisonReport
        {
            TestDocument = Path.GetFileName(testDocument),
            TestQueries = testQueries,
            StrategyResults = new Dictionary<string, StrategyResult>(),
            CompletedAt = DateTime.UtcNow
        };

        // ê° ì „ëµë³„ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        foreach (var strategy in _testStrategies)
        {
            Console.WriteLine($"\nğŸ” Testing Strategy: {strategy}");
            Console.WriteLine($"{"".PadLeft(40, '-')}");
            
            try
            {
                var strategyResult = await TestStrategyAsync(testDocument, testQueries, strategy, cancellationToken);
                report.StrategyResults[strategy] = strategyResult;
                
                Console.WriteLine($"âœ… {strategy} Complete - Avg Quality: {strategyResult.AverageQualityScore:F2}");
            }
            catch (Exception ex)
            {
                Console.WriteLine($"âŒ {strategy} Failed: {ex.Message}");
                report.StrategyResults[strategy] = new StrategyResult
                {
                    StrategyName = strategy,
                    Error = ex.Message,
                    TestResults = new List<QueryTestResult>()
                };
            }
        }

        // ê²°ê³¼ ë¶„ì„
        AnalyzeResults(report);
        
        Console.WriteLine("\nğŸ“Š Comparison Complete!");
        return report;
    }

    /// <summary>
    /// íŠ¹ì • ì „ëµìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    /// </summary>
    private async Task<StrategyResult> TestStrategyAsync(string testDocument, List<string> testQueries, string strategy, CancellationToken cancellationToken)
    {
        // 1. ë¬¸ì„œ ì²˜ë¦¬
        var options = new ChunkingOptions
        {
            Strategy = strategy,
            MaxChunkSize = 512,
            OverlapSize = 64
        };

        var chunkList = new List<DocumentChunk>();
        await foreach (var chunk in _processor.ProcessAsync(testDocument, options, cancellationToken))
        {
            chunkList.Add(chunk);
        }
        
        Console.WriteLine($"   Chunks created: {chunkList.Count}");

        // 2. ì„ë² ë”© ìƒì„±
        var embeddedChunks = new List<EmbeddedChunk>();
        foreach (var chunk in chunkList)
        {
            var embedding = await _embeddingService.GenerateEmbeddingAsync(chunk.Content, cancellationToken);
            embeddedChunks.Add(new EmbeddedChunk
            {
                Chunk = chunk,
                Embedding = embedding
            });
        }

        // 3. ê° ì¿¼ë¦¬ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        var queryResults = new List<QueryTestResult>();
        
        for (int i = 0; i < testQueries.Count; i++)
        {
            var query = testQueries[i];
            Console.WriteLine($"   Query {i + 1}/{testQueries.Count}: {TruncateString(query, 50)}");
            
            var queryResult = await TestQueryAsync(query, embeddedChunks, strategy, cancellationToken);
            queryResults.Add(queryResult);
        }

        // 4. ì „ëµë³„ ë©”íŠ¸ë¦­ ê³„ì‚°
        var strategyResult = new StrategyResult
        {
            StrategyName = strategy,
            TotalChunks = chunkList.Count,
            AverageChunkSize = chunkList.Average(c => c.Content.Length),
            TestResults = queryResults,
            AverageQualityScore = queryResults.Average(r => r.QualityScore),
            AverageRetrievalScore = queryResults.Average(r => r.RetrievalScore),
            AverageRelevanceScore = queryResults.Average(r => r.RelevanceScore)
        };

        // 5. ì²­í¬ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ê°€
        await CalculateChunkQualityMetrics(strategyResult, chunkList);

        return strategyResult;
    }

    /// <summary>
    /// ì¿¼ë¦¬ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    /// </summary>
    private async Task<QueryTestResult> TestQueryAsync(string query, List<EmbeddedChunk> embeddedChunks, string strategy, CancellationToken cancellationToken)
    {
        // ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        var queryEmbedding = await _embeddingService.GenerateEmbeddingAsync(query, cancellationToken);
        
        // ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        var similarities = embeddedChunks.Select(ec => new ChunkSimilarity
        {
            Chunk = ec.Chunk,
            Similarity = CosineSimilarity(queryEmbedding, ec.Embedding)
        }).OrderByDescending(cs => cs.Similarity).ToList();

        // Top-K ì²­í¬ ì„ íƒ (K=3)
        var topChunks = similarities.Take(3).ToList();
        
        // í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        var qualityScore = CalculateQualityScore(topChunks);
        var retrievalScore = CalculateRetrievalScore(topChunks, query);
        var relevanceScore = CalculateRelevanceScore(topChunks, query);

        return new QueryTestResult
        {
            Query = query,
            Strategy = strategy,
            TopChunks = topChunks,
            QualityScore = qualityScore,
            RetrievalScore = retrievalScore,
            RelevanceScore = relevanceScore,
            AvgSimilarity = topChunks.Average(tc => tc.Similarity),
            AvgChunkLength = topChunks.Average(tc => tc.Chunk.Content.Length)
        };
    }

    /// <summary>
    /// ì²­í¬ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
    /// </summary>
    private async Task CalculateChunkQualityMetrics(StrategyResult result, List<DocumentChunk> chunks)
    {
        // ì²­í¬ ì™„ì„±ë„ (ë¬¸ì¥ ê²½ê³„ ë³´ì¡´)
        var completeness = chunks.Average(c => CalculateCompletenessScore(c.Content));
        
        // ë¬¸ì¥ ë¬´ê²°ì„± (ì¤‘ê°„ì— ëŠì–´ì§„ ë¬¸ì¥ì´ ì—†ëŠ”ì§€)
        var integrity = chunks.Average(c => CalculateSentenceIntegrity(c.Content));
        
        // ì •ë³´ ë°€ë„ (ë‹¨ìœ„ ê¸¸ì´ë‹¹ ì •ë³´ëŸ‰)
        var density = chunks.Average(c => CalculateInformationDensity(c.Content));

        result.ChunkCompleteness = completeness;
        result.SentenceIntegrity = integrity;
        result.InformationDensity = density;
        
        await Task.CompletedTask; // ë¹„ë™ê¸° í˜¸í™˜
    }

    /// <summary>
    /// ë¬¸ì¥ ì™„ì„±ë„ ê³„ì‚°
    /// </summary>
    private double CalculateCompletenessScore(string content)
    {
        if (string.IsNullOrWhiteSpace(content)) return 0.0;

        var sentences = content.Split(new[] { '.', '!', '?' }, StringSplitOptions.RemoveEmptyEntries);
        if (sentences.Length == 0) return 0.0;

        var completeSentences = 0;
        foreach (var sentence in sentences)
        {
            var trimmed = sentence.Trim();
            if (!string.IsNullOrWhiteSpace(trimmed))
            {
                // ì™„ì „í•œ ë¬¸ì¥: "..." ë¡œ ëë‚˜ì§€ ì•Šê³ , ë¬¸ìë‚˜ ìˆ«ìë¡œ ëë‚˜ì§€ ì•ŠìŒ
                if (!trimmed.EndsWith("...") && !char.IsLetterOrDigit(trimmed.LastOrDefault()))
                {
                    completeSentences++;
                }
            }
        }

        return (double)completeSentences / sentences.Length;
    }

    /// <summary>
    /// ë¬¸ì¥ ë¬´ê²°ì„± ê³„ì‚°
    /// </summary>
    private double CalculateSentenceIntegrity(string content)
    {
        if (string.IsNullOrWhiteSpace(content)) return 0.0;

        var trimmed = content.Trim();
        
        // ë¯¸ì™„ì„± í‘œì‹œê°€ ìˆìœ¼ë©´ ì ìˆ˜ í•˜ë½
        if (trimmed.Contains("...") && !trimmed.Contains("etc."))
            return 0.5;
            
        // ë¬¸ì¥ì´ ì¤‘ê°„ì— ëŠê²¼ëŠ”ì§€ í™•ì¸
        var lastChar = trimmed.LastOrDefault();
        if (char.IsLetterOrDigit(lastChar) || lastChar == ',')
            return 0.3;
            
        return 1.0;
    }

    /// <summary>
    /// ì •ë³´ ë°€ë„ ê³„ì‚°
    /// </summary>
    private double CalculateInformationDensity(string content)
    {
        if (string.IsNullOrWhiteSpace(content)) return 0.0;

        var words = content.Split(new[] { ' ', '\n', '\r', '\t' }, StringSplitOptions.RemoveEmptyEntries);
        var uniqueWords = words.Where(w => w.Length > 3).Distinct().Count();
        var sentences = content.Split(new[] { '.', '!', '?' }, StringSplitOptions.RemoveEmptyEntries).Length;
        
        // ì •ë³´ ë°€ë„ = (ê³ ìœ  ë‹¨ì–´ ìˆ˜ + ë¬¸ì¥ ìˆ˜) / ì´ ë¬¸ì ìˆ˜ * 1000
        return (uniqueWords + sentences) * 1000.0 / content.Length;
    }

    /// <summary>
    /// ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    /// </summary>
    private double CosineSimilarity(float[] vec1, float[] vec2)
    {
        if (vec1.Length != vec2.Length)
            return 0.0;

        var dotProduct = vec1.Zip(vec2, (a, b) => a * b).Sum();
        var norm1 = Math.Sqrt(vec1.Sum(a => a * a));
        var norm2 = Math.Sqrt(vec2.Sum(b => b * b));

        if (norm1 == 0 || norm2 == 0)
            return 0.0;

        return dotProduct / (norm1 * norm2);
    }

    /// <summary>
    /// í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    /// </summary>
    private double CalculateQualityScore(List<ChunkSimilarity> topChunks)
    {
        if (topChunks.Count == 0) return 0.0;

        // ì²­í¬ í’ˆì§ˆ ì ìˆ˜ í‰ê· 
        return topChunks.Average(tc => tc.Chunk.QualityScore);
    }

    /// <summary>
    /// ê²€ìƒ‰ ì ìˆ˜ ê³„ì‚°
    /// </summary>
    private double CalculateRetrievalScore(List<ChunkSimilarity> topChunks, string query)
    {
        if (topChunks.Count == 0) return 0.0;

        // ìœ ì‚¬ë„ ì ìˆ˜ì— ìœ„ì¹˜ ê°€ì¤‘ì¹˜ ì ìš© (ìƒìœ„ ì²­í¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        var scores = new List<double>();
        for (int i = 0; i < topChunks.Count; i++)
        {
            var weight = 1.0 - (i * 0.2); // 1.0, 0.8, 0.6
            scores.Add(topChunks[i].Similarity * weight);
        }

        return scores.Average();
    }

    /// <summary>
    /// ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
    /// </summary>
    private double CalculateRelevanceScore(List<ChunkSimilarity> topChunks, string query)
    {
        if (topChunks.Count == 0) return 0.0;

        // ì¿¼ë¦¬ í‚¤ì›Œë“œì™€ ì²­í¬ ë‚´ìš©ì˜ ì¼ì¹˜ë„
        var queryWords = query.ToLowerInvariant().Split(' ', StringSplitOptions.RemoveEmptyEntries);
        var scores = new List<double>();

        foreach (var chunkSim in topChunks)
        {
            var chunkWords = chunkSim.Chunk.Content.ToLowerInvariant().Split(' ', StringSplitOptions.RemoveEmptyEntries);
            var matches = queryWords.Count(qw => chunkWords.Contains(qw));
            var relevance = queryWords.Length > 0 ? (double)matches / queryWords.Length : 0.0;
            scores.Add(relevance);
        }

        return scores.Average();
    }

    /// <summary>
    /// ê²°ê³¼ ë¶„ì„ ë° ìˆœìœ„ ë§¤ê¸°ê¸°
    /// </summary>
    private void AnalyzeResults(ComparisonReport report)
    {
        Console.WriteLine("\nğŸ“Š Analysis Results");
        Console.WriteLine("==================");

        // ì „ì²´ í’ˆì§ˆ ì ìˆ˜ë¡œ ìˆœìœ„ ë§¤ê¸°ê¸°
        var rankings = report.StrategyResults
            .Where(kvp => string.IsNullOrEmpty(kvp.Value.Error))
            .OrderByDescending(kvp => kvp.Value.AverageQualityScore)
            .ToList();

        Console.WriteLine("\nğŸ† Overall Quality Ranking:");
        for (int i = 0; i < rankings.Count; i++)
        {
            var result = rankings[i].Value;
            var icon = i == 0 ? "ğŸ¥‡" : i == 1 ? "ğŸ¥ˆ" : i == 2 ? "ğŸ¥‰" : "ğŸ“Š";
            
            Console.WriteLine($"{icon} {i + 1}. {result.StrategyName}");
            Console.WriteLine($"   Quality: {result.AverageQualityScore:F3}");
            Console.WriteLine($"   Retrieval: {result.AverageRetrievalScore:F3}");
            Console.WriteLine($"   Completeness: {result.ChunkCompleteness:F3}");
            Console.WriteLine($"   Integrity: {result.SentenceIntegrity:F3}");
            Console.WriteLine();
        }

        // ì„¸ë¶€ ë¶„ì„
        var bestStrategy = rankings.FirstOrDefault();
        if (bestStrategy.Value != null)
        {
            Console.WriteLine($"ğŸ¯ Best Strategy: {bestStrategy.Value.StrategyName}");
            Console.WriteLine($"   Chunks: {bestStrategy.Value.TotalChunks}");
            Console.WriteLine($"   Avg Size: {bestStrategy.Value.AverageChunkSize:F0} chars");
            Console.WriteLine($"   Quality: {bestStrategy.Value.AverageQualityScore:F3}");
        }
    }

    private string TruncateString(string input, int maxLength)
    {
        if (input.Length <= maxLength) return input;
        return input.Substring(0, maxLength - 3) + "...";
    }
}

// ì§€ì› í´ë˜ìŠ¤ë“¤
public class EmbeddedChunk
{
    public DocumentChunk Chunk { get; set; } = null!;
    public float[] Embedding { get; set; } = null!;
}

public class ChunkSimilarity
{
    public DocumentChunk Chunk { get; set; } = null!;
    public double Similarity { get; set; }
}

public class QueryTestResult
{
    public string Query { get; set; } = string.Empty;
    public string Strategy { get; set; } = string.Empty;
    public List<ChunkSimilarity> TopChunks { get; set; } = new();
    public double QualityScore { get; set; }
    public double RetrievalScore { get; set; }
    public double RelevanceScore { get; set; }
    public double AvgSimilarity { get; set; }
    public double AvgChunkLength { get; set; }
}

public class StrategyResult
{
    public string StrategyName { get; set; } = string.Empty;
    public int TotalChunks { get; set; }
    public double AverageChunkSize { get; set; }
    public List<QueryTestResult> TestResults { get; set; } = new();
    public double AverageQualityScore { get; set; }
    public double AverageRetrievalScore { get; set; }
    public double AverageRelevanceScore { get; set; }
    public double ChunkCompleteness { get; set; }
    public double SentenceIntegrity { get; set; }
    public double InformationDensity { get; set; }
    public string? Error { get; set; }
}

public class ComparisonReport
{
    public string TestDocument { get; set; } = string.Empty;
    public List<string> TestQueries { get; set; } = new();
    public Dictionary<string, StrategyResult> StrategyResults { get; set; } = new();
    public DateTime CompletedAt { get; set; }
}

public class TestResult
{
    public string StrategyName { get; set; } = string.Empty;
    public double QualityScore { get; set; }
    public double CompletenessScore { get; set; }
    public double RetrievalAccuracy { get; set; }
    public int ChunkCount { get; set; }
    public double AvgChunkSize { get; set; }
}