using FileFlux;
using FileFlux.Core;
using FileFlux.Domain;
using FileFlux.Tests.Mocks;
using FileFlux.Infrastructure.Services;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using OpenAI;
using TestConsoleApp;
using System.Text.Json;

// Simple PDF test console app
// var path = @"D:\test-data\ì±„ë³€í”„ë¡œê·¸ë¨ ë³€ê²½[25.02.03].pdf";
var path = @"D:\data\FileFlux\test\test-pdf\oai_gpt-oss_model_card.pdf";

Console.WriteLine("FileFlux PDF Processing Test");
Console.WriteLine($"Processing: {path}");
Console.WriteLine(new string('=', 50));

// Load environment variables from .env.local
EnvLoader.LoadFromFile();
var hasOpenAI = EnvLoader.ValidateOpenAIConfig();

// Setup DI container with FileFlux services
var services = new ServiceCollection();
services.AddLogging(builder => builder.AddConsole());

// Register FileFlux services
services.AddFileFlux();

// Configure AI services based on availability
if (hasOpenAI)
{
    Console.WriteLine("\nğŸš€ Using OpenAI services for enhanced processing...");

    var apiKey = Environment.GetEnvironmentVariable("OPENAI_API_KEY")!;
    var model = Environment.GetEnvironmentVariable("OPENAI_MODEL") ?? "gpt-5-nano";

    var openAiClient = new OpenAIClient(apiKey);
    var chatClient = openAiClient.GetChatClient(model);

    services.AddSingleton(chatClient);
    services.AddSingleton<ITextCompletionService, OpenAiTextCompletionService>();
    services.AddSingleton<IImageToTextService>(provider => new OpenAiImageToTextService(apiKey));
}
else
{
    Console.WriteLine("\nâš ï¸ Using Mock services (OpenAI not configured)");
    services.AddSingleton<ITextCompletionService, MockTextCompletionService>();
    services.AddSingleton<IImageToTextService, MockImageToTextService>();
}

var serviceProvider = services.BuildServiceProvider();
var processingService = serviceProvider.GetRequiredService<IDocumentProcessor>();

var chunks = new List<DocumentChunk>();

try
{
    Console.WriteLine("Starting document processing...\n");

    // Simple processing without complex options - just use the processor directly

    await foreach (var chunk in processingService.ProcessAsync(path))
    {
        chunks.Add(chunk);

        // Display progress
        if (chunks.Count % 10 == 0 || chunks.Count <= 5)
        {
            Console.WriteLine($"Processed chunk #{chunks.Count}: {chunk.Content.Length} chars, Quality: {chunk.QualityScore:F2}");
        }
    }

    Console.WriteLine($"\nâœ… Processing Complete!");
    Console.WriteLine(new string('=', 50));
    Console.WriteLine($"ğŸ“„ Total chunks: {chunks.Count}");
    Console.WriteLine($"ğŸ“Š Average quality score: {chunks.Average(c => c.QualityScore):F2}");
    Console.WriteLine($"ğŸ“ Total characters: {chunks.Sum(c => c.Content.Length):N0}");
    Console.WriteLine($"â±ï¸ Average chunk size: {chunks.Average(c => c.Content.Length):F0} chars");
    Console.WriteLine($"ğŸ¤– AI Service: {(hasOpenAI ? "OpenAI GPT-5-nano" : "Mock Service")}");

    // Show first few chunks
    Console.WriteLine("\nğŸ“‹ First 3 chunks preview:");
    Console.WriteLine(new string('-', 50));

    for (int i = 0; i < Math.Min(3, chunks.Count); i++)
    {
        var chunk = chunks[i];
        var preview = chunk.Content.Length > 200
            ? chunk.Content[..200] + "..."
            : chunk.Content;

        Console.WriteLine($"\nChunk {i + 1} (Quality: {chunk.QualityScore:F2}):");
        Console.WriteLine(preview.Replace('\n', ' ').Replace('\r', ' '));
    }

    // Metadata information
    if (chunks.Any())
    {
        var firstChunk = chunks.First();
        Console.WriteLine($"\nğŸ“‹ Document Metadata:");
        Console.WriteLine($"  - Source: {path}");
        Console.WriteLine($"  - Chunk ID: {firstChunk.Id}");
        Console.WriteLine($"  - Position: {firstChunk.StartPosition}-{firstChunk.EndPosition}");
        Console.WriteLine($"  - Strategy: {firstChunk.Strategy}");
    }
}
catch (Exception ex)
{
    Console.WriteLine($"âŒ Error processing document: {ex.Message}");
    Console.WriteLine($"Stack trace: {ex.StackTrace}");
    return 1;
}

    // Save results to output directory
    Directory.CreateDirectory("output");

    // Save chunk details to JSON
    var chunkData = chunks.Select(c => new {
        Id = c.Id,
        Content = c.Content,
        QualityScore = c.QualityScore,
        StartPosition = c.StartPosition,
        EndPosition = c.EndPosition,
        Strategy = c.Strategy,
        ContentType = c.ContentType,
        StructuralRole = c.StructuralRole,
        TechnicalKeywords = c.TechnicalKeywords,
        Properties = c.Properties,
        Importance = c.Importance,
        RelevanceScore = c.RelevanceScore,
        TopicCategory = c.TopicCategory,
        DocumentDomain = c.DocumentDomain,
        CreatedAt = c.CreatedAt
    }).ToArray();

    var jsonOptions = new JsonSerializerOptions {
        WriteIndented = true,
        Encoder = System.Text.Encodings.Web.JavaScriptEncoder.UnsafeRelaxedJsonEscaping
    };

    var timestamp = DateTime.Now.ToString("yyyyMMdd_HHmmss");
    var chunkFile = $"output/chunks_openai_{timestamp}.json";
    await File.WriteAllTextAsync(chunkFile, JsonSerializer.Serialize(chunkData, jsonOptions));

    // Save summary report
    var summaryReport = $"""
        FileFlux ì‹¤ì œ API í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ
        ========================================

        í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {DateTime.Now:yyyy-MM-dd HH:mm:ss}
        ì…ë ¥ íŒŒì¼: {path}
        AI ì„œë¹„ìŠ¤: {(hasOpenAI ? "OpenAI GPT-5-nano" : "Mock Service")}

        ì²˜ë¦¬ ê²°ê³¼:
        - ì´ ì²­í¬ ìˆ˜: {chunks.Count}
        - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {chunks.Average(c => c.QualityScore):F2}
        - ì´ ë¬¸ì ìˆ˜: {chunks.Sum(c => c.Content.Length):N0}
        - í‰ê·  ì²­í¬ í¬ê¸°: {chunks.Average(c => c.Content.Length):F0} ë¬¸ì

        í™˜ê²½ ì„¤ì •:
        - OpenAI API Key: {(hasOpenAI ? "âœ… ì„¤ì •ë¨" : "âŒ ë¯¸ì„¤ì •")}
        - ëª¨ë¸: {Environment.GetEnvironmentVariable("OPENAI_MODEL") ?? "N/A"}
        - ì„ë² ë”© ëª¨ë¸: {Environment.GetEnvironmentVariable("OPENAI_EMBEDDING_MODEL") ?? "N/A"}

        íŒŒì¼ ì¶œë ¥:
        - ì²­í¬ ìƒì„¸ ë°ì´í„°: {chunkFile}
        - ì‹¤í–‰ ë¡œê·¸: output/test_execution_log.txt
        """;

    var reportFile = $"output/test_report_openai_{timestamp}.md";
    await File.WriteAllTextAsync(reportFile, summaryReport);

    Console.WriteLine($"\nğŸ“ Results saved to:");
    Console.WriteLine($"  - Chunks: {chunkFile}");
    Console.WriteLine($"  - Report: {reportFile}");

Console.WriteLine("\nâœ¨ Test completed successfully!");

// Run Phase 15 improved test
Console.WriteLine("\n" + new string('=', 70));
Console.WriteLine("ğŸš€ Running Phase 15 IMPROVED Test (Enhanced Chunking)...");
Console.WriteLine(new string('=', 70));

await ImprovedTestProgram.RunImprovedTest();

// Run Force Smart test for comparison
Console.WriteLine("\n" + new string('=', 70));
Console.WriteLine("âš¡ Running FORCE SMART Test (Direct Strategy)...");
Console.WriteLine(new string('=', 70));

await ForceSmartTestProgram.RunForceSmartTest();

// Run Force Small Chunk test for final verification
Console.WriteLine("\n" + new string('=', 70));
Console.WriteLine("ğŸ”¥ Running FORCE SMALL CHUNK Test (Final Verification)...");
Console.WriteLine(new string('=', 70));

await ForceSmallChunkTestProgram.RunForceSmallChunkTest();

// Run additional Mock-only test for comparison
Console.WriteLine("\n" + new string('=', 60));
Console.WriteLine("ğŸ”„ Running Mock Service Comparison Test...");
Console.WriteLine(new string('=', 60));

await MockTestProgram.RunMockTest();

return 0;