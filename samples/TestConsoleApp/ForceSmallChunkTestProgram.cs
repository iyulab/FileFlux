using FileFlux;
using FileFlux.Core;
using FileFlux.Domain;
using FileFlux.Tests.Mocks;
using FileFlux.Infrastructure.Services;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using OpenAI;
using System.Text.Json;

namespace TestConsoleApp;

/// <summary>
/// ë§¤ìš° ì‘ì€ ì²­í¬ í¬ê¸°ë¥¼ ê°•ì œí•˜ëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨
/// </summary>
public static class ForceSmallChunkTestProgram
{
    public static async Task RunForceSmallChunkTest()
    {
        var path = @"D:\test-data\ì±„ë³€í”„ë¡œê·¸ë¨ ë³€ê²½[25.02.03].pdf";

        Console.WriteLine("FileFlux PDF Processing Test (FORCE SMALL CHUNKS)");
        Console.WriteLine($"Processing: {path}");
        Console.WriteLine(new string('=', 60));

        // Load environment variables from .env.local
        EnvLoader.LoadFromFile();
        var hasOpenAI = EnvLoader.ValidateOpenAIConfig();

        // Setup DI container with FileFlux services
        var services = new ServiceCollection();
        services.AddLogging(builder => builder.AddConsole());

        // Register FileFlux services
        services.AddFileFlux();

        // Configure AI services based on availability
        if (hasOpenAI)
        {
            Console.WriteLine("\nğŸš€ Using OpenAI services for SMALL CHUNK processing...");

            var apiKey = Environment.GetEnvironmentVariable("OPENAI_API_KEY")!;
            var model = Environment.GetEnvironmentVariable("OPENAI_MODEL") ?? "gpt-5-nano";

            var openAiClient = new OpenAIClient(apiKey);
            var chatClient = openAiClient.GetChatClient(model);

            services.AddSingleton(chatClient);
            services.AddSingleton<IDocumentAnalysisService, OpenAiTextCompletionService>();
            services.AddSingleton<IImageToTextService>(provider => new OpenAiImageToTextService(apiKey));
        }
        else
        {
            Console.WriteLine("\nâš ï¸ Using Mock services (OpenAI not configured)");
            services.AddSingleton<IDocumentAnalysisService, MockTextCompletionService>();
            services.AddSingleton<IImageToTextService, MockImageToTextService>();
        }

        var serviceProvider = services.BuildServiceProvider();
        var processingService = serviceProvider.GetRequiredService<IDocumentProcessor>();

        var chunks = new List<DocumentChunk>();

        try
        {
            Console.WriteLine("Starting SMALL CHUNK document processing...\n");

            // ë§¤ìš° ì‘ì€ ì²­í¬ í¬ê¸°ë¡œ ê°•ì œ ë¶„í• 
            var smallChunkOptions = new ChunkingOptions
            {
                Strategy = ChunkingStrategies.Sentence,  // Sentence ì „ëµ ì‚¬ìš©
                MaxChunkSize = 300,                   // ë§¤ìš° ì‘ì€ ì²­í¬ í¬ê¸° (300ì)
                OverlapSize = 30                      // ì‘ì€ ì˜¤ë²„ë©
            };

            // ê°•ì œ ë¶„í•  ì˜µì…˜ ì¶”ê°€
            smallChunkOptions.CustomProperties["MinCompleteness"] = 0.6; // ì™„ì„±ë„ ê¸°ì¤€ ì™„í™”
            smallChunkOptions.CustomProperties["PreserveSentences"] = true;
            smallChunkOptions.CustomProperties["ForceSmallChunks"] = true;
            smallChunkOptions.CustomProperties["AggressiveSplit"] = true;

            await foreach (var chunk in processingService.ProcessAsync(path, smallChunkOptions))
            {
                chunks.Add(chunk);

                // Display progress
                Console.WriteLine($"Chunk #{chunks.Count}: {chunk.Content.Length} chars, Quality: {chunk.QualityScore:F2}");
            }

            Console.WriteLine($"\nâœ… SMALL CHUNK Processing Complete!");
            Console.WriteLine(new string('=', 60));
            Console.WriteLine($"ğŸ“„ Total chunks: {chunks.Count}");
            Console.WriteLine($"ğŸ“Š Average quality score: {chunks.Average(c => c.QualityScore):F2}");
            Console.WriteLine($"ğŸ“ Total characters: {chunks.Sum(c => c.Content.Length):N0}");
            Console.WriteLine($"â±ï¸ Average chunk size: {chunks.Average(c => c.Content.Length):F0} chars");
            Console.WriteLine($"ğŸ¤– AI Service: {(hasOpenAI ? "OpenAI GPT-5-nano" : "Mock Service")} (SMALL CHUNKS)");

            // Show all chunks
            Console.WriteLine($"\nğŸ“‹ All {chunks.Count} chunks preview:");
            Console.WriteLine(new string('-', 60));

            for (int i = 0; i < chunks.Count; i++)
            {
                var chunk = chunks[i];
                var preview = chunk.Content.Length > 100
                    ? chunk.Content[..100] + "..."
                    : chunk.Content;

                Console.WriteLine($"\n--- Chunk {i + 1} (Quality: {chunk.QualityScore:F2}, Size: {chunk.Content.Length}) ---");
                Console.WriteLine(preview.Replace('\n', ' ').Replace('\r', ' '));
            }

            // ìƒì„¸í•œ ë©”íƒ€ë°ì´í„° ì •ë³´
            if (chunks.Any())
            {
                Console.WriteLine($"\nğŸ“‹ Detailed Metadata (SMALL CHUNKS):");
                Console.WriteLine($"  - Source: {path}");
                Console.WriteLine($"  - Processing Strategy: {chunks.First().Strategy}");
                Console.WriteLine($"  - Content Types: {string.Join(", ", chunks.Select(c => c.ContentType).Distinct())}");
                Console.WriteLine($"  - Quality Range: {chunks.Min(c => c.QualityScore):F2} - {chunks.Max(c => c.QualityScore):F2}");
                Console.WriteLine($"  - Size Range: {chunks.Min(c => c.Content.Length)} - {chunks.Max(c => c.Content.Length)} chars");
            }

            // Save small chunk results
            await SaveSmallChunkResults(chunks, hasOpenAI, path);
        }
        catch (Exception ex)
        {
            Console.WriteLine($"âŒ Error processing document: {ex.Message}");
            Console.WriteLine($"Stack trace: {ex.StackTrace}");
        }

        Console.WriteLine("\nâœ¨ SMALL CHUNK Test completed successfully!");
    }

    private static async Task SaveSmallChunkResults(List<DocumentChunk> chunks, bool hasOpenAI, string path)
    {
        Directory.CreateDirectory("output");

        var timestamp = DateTime.Now.ToString("yyyyMMdd_HHmmss");

        // Save chunk details to JSON
        var chunkData = chunks.Select(c => new {
            Id = c.Id,
            Content = c.Content,
            QualityScore = c.QualityScore,
            StartPosition = c.StartPosition,
            EndPosition = c.EndPosition,
            Strategy = c.Strategy,
            ContentType = c.ContentType,
            StructuralRole = c.StructuralRole,
            TechnicalKeywords = c.TechnicalKeywords,
            Properties = c.Properties,
            Importance = c.Importance,
            RelevanceScore = c.RelevanceScore,
            TopicCategory = c.TopicCategory,
            DocumentDomain = c.DocumentDomain,
            CreatedAt = c.CreatedAt
        }).ToArray();

        var jsonOptions = new JsonSerializerOptions {
            WriteIndented = true,
            Encoder = System.Text.Encodings.Web.JavaScriptEncoder.UnsafeRelaxedJsonEscaping
        };

        var chunkFile = $"output/chunks_small_chunks_{timestamp}.json";
        await File.WriteAllTextAsync(chunkFile, JsonSerializer.Serialize(chunkData, jsonOptions));

        // Save small chunk report
        var smallChunkReport = $"""
            FileFlux SMALL CHUNK ê°•ì œ ë¶„í•  í…ŒìŠ¤íŠ¸ ê²°ê³¼
            =========================================

            í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {DateTime.Now:yyyy-MM-dd HH:mm:ss}
            ì…ë ¥ íŒŒì¼: {path}
            ê°•ì œ ì „ëµ: Smart (MaxChunkSize=300)
            AI ì„œë¹„ìŠ¤: {(hasOpenAI ? "OpenAI GPT-5-nano" : "Mock Service")}

            Small Chunk ê²°ê³¼:
            - ì´ ì²­í¬ ìˆ˜: {chunks.Count}ê°œ
            - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {chunks.Average(c => c.QualityScore):F2}
            - ì´ ë¬¸ì ìˆ˜: {chunks.Sum(c => c.Content.Length):N0}
            - í‰ê·  ì²­í¬ í¬ê¸°: {chunks.Average(c => c.Content.Length):F0} ë¬¸ì
            - í’ˆì§ˆ ë²”ìœ„: {chunks.Min(c => c.QualityScore):F2} - {chunks.Max(c => c.QualityScore):F2}
            - í¬ê¸° ë²”ìœ„: {chunks.Min(c => c.Content.Length)} - {chunks.Max(c => c.Content.Length)} ë¬¸ì

            ì„¤ì •:
            - ìµœëŒ€ ì²­í¬ í¬ê¸°: 300ì (ê°•ì œ ë¶„í• )
            - ì˜¤ë²„ë© í¬ê¸°: 30ì
            - ì™„ì„±ë„ ê¸°ì¤€: 0.6 (ì™„í™”)
            - ê°•ì œ ë¶„í• : True

            ğŸ“Š ë¶„í•  ì„±ê³µ ì—¬ë¶€:
            {(chunks.Count > 1 ? "âœ… ì„±ê³µ - ë¬¸ì„œê°€ ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• ë¨" : "âŒ ì‹¤íŒ¨ - ì—¬ì „íˆ ë‹¨ì¼ ì²­í¬")}

            ì²­í¬ë³„ ìƒì„¸ ì •ë³´:
            """;

        for (int i = 0; i < chunks.Count; i++)
        {
            var chunk = chunks[i];
            smallChunkReport += $"""

            ì²­í¬ {i + 1}:
            - í¬ê¸°: {chunk.Content.Length}ì
            - í’ˆì§ˆ: {chunk.QualityScore:F2}
            - ì „ëµ: {chunk.Strategy}
            - íƒ€ì…: {chunk.ContentType}
            - ì¤‘ìš”ë„: {chunk.Importance:F2}
            - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {(chunk.Content.Length > 100 ? chunk.Content[..100] + "..." : chunk.Content).Replace('\n', ' ')}
            """;
        }

        var reportFile = $"output/small_chunk_report_{timestamp}.md";
        await File.WriteAllTextAsync(reportFile, smallChunkReport);

        Console.WriteLine($"\nğŸ“ Small Chunk results saved to:");
        Console.WriteLine($"  - Chunks: {chunkFile}");
        Console.WriteLine($"  - Report: {reportFile}");
    }
}